<!DOCTYPE html>
<html lang="kr">

<head>
  <meta charset="UTF-8">
  <meta name="description" content="test WebRTC">
  <meta name="viewport" content="width=device-width, user-scalable=yes, initial-scale=1, maximum-scale=1">
  <link rel="stylesheet" href="../commons/css/main.css" />
</head>

<body>
  <div id="container">
    <h1>참여자</h1>
    <video id="localVideo" playsinline autoplay muted></video>
    <canvas></canvas>
    <div>
      <button id="startButton">시작</button>
      <button id="callButton">방 생성</button>
      <button id="hangupButton">방 나가기</button>
    </div>
    <div id="volumeMeter">
      <div class="volumeBar"></div>
      <div class="volumeBar"></div>
      <div class="volumeBar"></div>
      <div class="volumeBar"></div>
      <div class="volumeBar"></div>

      <div class="volumeBar"></div>
      <div class="volumeBar"></div>
      <div class="volumeBar"></div>
      <div class="volumeBar"></div>
      <div class="volumeBar"></div>
    </div>
    <audio id="localAudio" playsinline autoplay muted></audio>
  </div>
  <script type="module">
    import { io } from "https://cdn.socket.io/4.4.1/socket.io.esm.min.js";
    const socket = io('http://localhost:3000/enter-room');

    const startButton = document.getElementById('startButton');
    const callButton = document.getElementById('callButton');
    const hangupButton = document.getElementById('hangupButton');
    callButton.disabled = true;
    hangupButton.disabled = true;
    let onFrameId = null;

    const canvas = document.querySelector('canvas');
    const localVideo = document.getElementById('localVideo');
    const localAudio = document.getElementById('localAudio');

    let localStream = undefined;
    let presenterRTCPC;
    let tmp = []
    const pc_config = {
      iceServers: [
        {
          urls: [
            "stun:stun.l.google.com:19302",
          ]
        },
      ],
    };


    const start = async () => {
      await initConnection();
      presenterRTCPC.ontrack = (event) => {
        if (event.track.kind === 'audio') {
          localStream.addTrack(event.track)
          analyser();
          console.log("audio", event.track)
          localAudio.srcObject = localStream;
        } else if (event.track.kind === 'video') {
          localStream.addTrack(event.track)
          localVideo.srcObject = localStream;
        }
      }

      await getStream();
    }

    const initConnection = async () => {
      try {
        presenterRTCPC = new RTCPeerConnection();
        const stream = new MediaStream();
        localStream = stream;
      } catch (e) {
        console.log(e)
      }
    }


    async function getStream() {
      try {
        await createStudentOffer();
        await setServerAnswer();
      } catch (e) {
        console.log(e);
      }
    }

    function getStudentCandidate() {
      presenterRTCPC.onicecandidate = (e) => {
        if (e.candidate) {
          socket.emit('studentCandidate', {
            candidate: e.candidate,
            studentSocketId: socket.id
          });
        }
      }
    }

    async function createStudentOffer() {
      try {
        const SDP = await presenterRTCPC.createOffer({
          offerToReceiveAudio: true,
          offerToReceiveVideo: true
        });
        socket.emit('studentOffer', {
          socketId: socket.id,
          SDP: SDP
        });

        presenterRTCPC.setLocalDescription(SDP);
        getStudentCandidate()
      } catch (e) {
        console.log(e);
      }
    }

    async function setServerAnswer() {
      socket.on(`${socket.id}-serverAnswer`, (data) => {
        presenterRTCPC.setRemoteDescription(data.SDP)
      })
      socket.on(`${socket.id}-serverCandidate`, (data) => {
        presenterRTCPC.addIceCandidate(new RTCIceCandidate(data.candidate))
      });
    }


    const analyser = () => {
      console.log(localStream)
      const context = new AudioContext();
      const analyser = context.createAnalyser();
      const mediaStreamAudioSourceNode =
        context.createMediaStreamSource(localStream);
      mediaStreamAudioSourceNode.connect(analyser, 0);
      const pcmData = new Float32Array(analyser.fftSize);

      const onFrame = () => {
        analyser.getFloatTimeDomainData(pcmData);
        let sum = 0.0;
        for (const amplitude of pcmData) {
          sum += amplitude * amplitude;
        }
        const rms = Math.sqrt(sum / pcmData.length);
        const normalizedVolume = Math.min(1, rms / 0.5);
        colorVolumeMeter(normalizedVolume * 2);
        onFrameId = window.requestAnimationFrame(onFrame);
      };

      onFrameId = window.requestAnimationFrame(onFrame);

      const audioStream = getAudioStream();
      setupAudioContext(audioStream);
    }

    const normalizeToInteger = (volume, min, max) => {
      const scaledValue = Math.min(max, Math.max(min, volume * (max - min) + min));
      return Math.round(scaledValue);
    };

    const colorVolumeMeter = (vol) => {
      const VOL_METER_MAX = 10;
      const childrens = document.querySelectorAll(".volumeBar");

      childrens.forEach((child) => {
        child.style.backgroundColor = "#e6e6e6";
      });

      const numberOfChildToColor = normalizeToInteger(vol, 0, VOL_METER_MAX);
      const coloredChild = Array.from(childrens).slice(0, numberOfChildToColor);

      coloredChild.forEach((child) => {
        child.style.backgroundColor = "#4F4FFB";
      });
    };



    function getAudioStream() {
      const audioTracks = localStream.getAudioTracks();
      const audioStream = new MediaStream(audioTracks);
      return audioStream;
    }

    function setupAudioContext(stream) {
      const audioContext = new AudioContext();
      const source = audioContext.createMediaStreamSource(stream);
      const destination = audioContext.destination;

      source.connect(destination);
    }

    startButton.onclick = start;
  </script>
  <script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
  <script src="../commons/js/streamVisualizer.js"></script>
</body>

</html>